# Google Advanced Data Analytics Professional Certificate Projects

This repository contains the projects completed as part of the Google Advanced Data Analytics Professional Certificate program. The program focuses on developing skills in data analysis, data visualization, and machine learning using Google Cloud Platform (GCP) tools and services.
## Table of Contents
- [00. Certificate Program Overview](#abstract-main)
- [01. Projects Overview](#project-overview)


## Certificate Program Overview <a name="abstract-main"></a>

The Google Advanced Data Analytics Professional Certificate program is a comprehensive learning path that covers a range of topics related to data analysis and machine learning. The program consists of the following courses:

1. **Foundations of Data Science**
   - Introduction to data science and its significance in the modern world.
   - Understanding data types, data sources, and data quality.
   - Exploratory data analysis techniques.
   - Basic statistical concepts and measures.
   - Data cleaning and preprocessing techniques.
   - Introduction to data visualization.
   - Using Python libraries for data analysis (e.g., Pandas, NumPy).
   - 
2. **Get Started With Python**
   - Gain a solid foundation in Python programming.
   - Learn how to write Python scripts and programs for data analysis tasks.
   - Understand Python's syntax, data structures, and control flow.
   - Familiarize yourself with popular Python libraries for data analysis.
   - Develop the ability to work with data in various formats and structures using Python.

3. **Go Beyond the Numbers: Translate Data into Insights**
   - Learn techniques to analyze and interpret data effectively.
   - Applying statistical methods to analyze data and draw meaningful conclusions.
   - Develop skills to extract actionable insights from data.
   - Understand best practices for data storytelling and visualization.
   - Learn to effectively communicate data-driven insights to stakeholders.
   - Exploratory data analysis (EDA) techniques to uncover patterns and trends in data.
   - Data visualization principles and best practices.
   - Using storytelling techniques to communicate data insights effectively.
   - Presenting data-driven insights using clear and compelling visualizations.
  
4. **Power of Statistics**
   - Gain a solid foundation in statistical concepts and methodologies.
   - Learn how to apply statistical techniques to analyze and interpret data.
   - Understand the role of statistics in data-driven decision making.
   - Develop skills to draw meaningful conclusions from data using statistical inference.
   - Introduction to statistical concepts and terminology.
   - Descriptive statistics: measures of central tendency and variability.
   - Probability distributions and hypothesis testing.
   - Confidence intervals and margin of error.
   - Statistical inference and significance testing.
 
5. **Regression Analysis: Simplify Complex Data Relationships**
   - Learn regression analysis concepts and methodologies.
   - Understand how to build regression models to analyze and predict outcomes.
   - Gain practical skills in implementing regression models using appropriate tools.
   - Learn techniques to interpret and evaluate regression model results.
   - Introduction to regression analysis and its applications.
   - Simple linear regression and multiple linear regression techniques.
   - Model building, feature selection, and variable transformation.
   - Evaluating regression model performance and interpreting results.
   - Handling and addressing common challenges in regression analysis.

6. **The Nuts and Bolts of Machine Learning**
   - Gain a solid understanding of machine learning principles and methodologies.
   - Learn how to apply machine learning algorithms to solve real-world problems.
   - Understand the different types of machine learning algorithms and their applications.
   - Develop skills in training, evaluating, and deploying machine learning models.
   - Introduction to machine learning concepts, supervised and unsupervised learning.
   - Types of machine learning algorithms: classification, regression, clustering, and dimensionality reduction.
   - Data preprocessing, feature engineering, and feature selection.
   - Model training, evaluation, and validation techniques.
   - Deploying machine learning models in production.
  
7. **Google Advanced Data Analytics Capstone**
   - Apply the acquired knowledge and skills to solve a complex data analytics problem.
   - Demonstrate proficiency in data analysis, machine learning, and data visualization.
   - Develop a comprehensive solution by leveraging GCP tools and services.
   - Communicate findings effectively and present actionable insights.
   - Define a clear problem statement and project scope.
   - Acquire, clean, and preprocess relevant datasets.
   - Conduct exploratory data analysis (EDA) to gain insights and identify patterns.
   - Develop and apply appropriate machine learning algorithms/models.
   - Evaluate and fine-tune the models for optimal performance.
   - Create visualizations and dashboards to communicate insights.
   - Present the project findings in a clear and compelling manner.

## Projects Overview <a name="project-overview"></a>

This repository contains the projects completed as part of the Google Advanced Data Analytics Professional Certificate program. Each project, three which span the whole set of seven courses, focuses on applying the knowledge gained from the corresponding course and showcases practical skills in data analysis, data transformation, data visualization, and machine learning.

The projects included in this repository are as follows:

1. [Project 1: New York City Taxi and Limousine Commission (TLC)](https://github.com/EfthimiosVlahos/Google-Advanced-Data-Analytics-Professional-Certificate-Projects/blob/main/Exemplar_Course%203%20Automatidata%20project%20lab.ipynb)

- Automatidata is consulting for the New York City Taxi and Limousine Commission (TLC). New York City TLC is an agency responsible for licensing and regulating New York City's taxi cabs and for-hire vehicles. The agency has partnered with Automatidata to develop a regression model that helps estimate taxi fares before the ride, based on data that TLC has gathered. 

Note: This project's dataset was created for pedagogical purposes and may not be indicative of New York City taxi cab riders' behavior.

### Overview

   **1.1. Project Proposal and Milestones:**
      - Create a project proposal outlining the objectives, scope, and deliverables of the TLC project.
      - Define milestones and set timelines for the tasks within the project.
      - Identify the key stakeholders and establish communication channels.
   
   **1.2. Building the DataFrame and Organizing Claims Data:**
      - Build a DataFrame using the TLC data, ensuring data integrity and consistency.
      - Organize the claims data for further analysis, including data cleaning and preprocessing.
      - Update the project team on the progress made and share initial insights from the data.
   
   **1.3.Exploratory Data Analysis (EDA) and Visualization:**
      - Conduct exploratory data analysis on the TLC data to understand its characteristics and patterns.
      - Utilize Tableau or similar tools to create visuals and dashboards for an executive summary.
      - Present the visualizations to non-technical stakeholders, allowing them to engage and interact with the data.
   
   **1.4.Hypothesis Testing:**
      - Perform hypothesis testing on the TLC dataset to investigate specific research questions.
      - Select the appropriate hypothesis testing method that best serves the data and the goals of the TLC project.
      - Document and communicate the findings and implications of the hypothesis testing.
   
   **1.5.Modeling Approach and Regression Model Building:**
      - Determine the correct modeling approach based on the project requirements.
      - Build a regression model using the TLC dataset, considering appropriate variables and predictors.
      - Verify the model assumptions and perform necessary checks for model validation.
      - Evaluate the model's performance using appropriate metrics and statistical techniques.
      - Interpret the results of the regression model and summarize the findings for stakeholders at TLC.
   
   **1.6.Model Evaluation and Summarizing Findings:**
      - Perform further model evaluation to assess its accuracy, precision, and generalizability.
      - Summarize the findings and insights from the regression model for both Automatidata and stakeholders at TLC.
      - Communicate the results effectively, highlighting the model's predictive capabilities and its implications for decision-making.

2. [Project 2: TikTok](https://github.com/EfthimiosVlahos/Google-Advanced-Data-Analytics-Professional-Certificate-Projects/blob/main/Exemplar_Course%202%20TikTok%20project%20lab%20(1).ipynb)

- At TikTok, our mission is to inspire creativity and bring joy. Our employees lead with curiosity and move at the speed of culture. Combined with our company's flat structure, you'll be given dynamic opportunities to make a real impact on a rapidly expanding company and grow your career. TikTok users have the ability to report videos and comments that contain user claims. These reports identify content that needs to be reviewed by moderators. This process generates a large number of user reports that are difficult to address quickly. TikTok is working on the development of a predictive model that can determine whether a video contains a claim or offers an opinion. With a successful prediction model, TikTok can reduce the backlog of user reports and prioritize them more efficiently.


### Overview

   **2.1. Project Proposal and Milestones:**
      - Create a project proposal outlining milestones for the tasks within the comment classification project.
      - Consider the audience, project goals, team dynamics, and the PACE (Plan, Analyze, Communicate, Execute) stages while planning project deliverables.
   
   **2.2. EDA, Data Cleaning, and Visualization Selection:**
      - Perform exploratory data analysis (EDA) and cleaning on the TikTok claims data.
      - Select the appropriate visualization type(s) to represent variables and relationships within the data.
      - Create plots and visualizations to effectively communicate insights and patterns to the TikTok team.
   
   **2.3.EDA, Data Cleaning, and Visualization Sharing:**
      - Continue with EDA and data cleaning tasks for the TikTok claims classification project.
      - Select and build appropriate visualization types to explore variables and relationships.
      - Share the results and findings with the TikTok team, ensuring effective communication of insights.
   
   **2.4.Project Data Exploration and Hypothesis Testing:**
      - Explore the project data further to uncover patterns and relationships.
      - Implement a hypothesis test to validate assumptions or investigate specific research questions.
      - Communicate insights and findings with stakeholders within TikTok, ensuring clear and concise reporting.
   
   **2.5.Regression Model Building for Claims Classification:**
      - Develop a regression model for the TikTok claims classification data.
      - Determine the appropriate type of regression model based on the project requirements.
      - Utilize TikTok's claim classification data to build and train the regression model.
   
   **2.6.Model Building, Model Evaluation, and Findings Summary:**
      - Proceed with model building for the claims classification project within TikTok's data team.
      - Evaluate the performance of the developed model through appropriate metrics and techniques.
      - Summarize the findings and insights derived from the model for cross-departmental stakeholders within TikTok.

3. [Project 3: Waze](https://github.com/EfthimiosVlahos/Google-Advanced-Data-Analytics-Professional-Certificate-Projects/blob/main/Exemplar_Course%202%20Waze%20project%20lab%20(1).ipynb)

- Waze’s free navigation app makes it easier for drivers around the world to get to where they want to go. Waze’s community of map editors, beta testers, translators, partners, and users helps make each drive better and safer. Waze partners with cities, transportation authorities, broadcasters, businesses, and first responders to help as many people as possible travel more efficiently and safely. You’ll collaborate with your Waze teammates to analyze and interpret data, generate valuable insights, and help leadership make informed business decisions. Your team is about to start a new project to help prevent user churn on the Waze app. Churn quantifies the number of users who have uninstalled the Waze app or stopped using the app. This project focuses on monthly user churn. In your role, you will analyze user data and develop a machine learning model that predicts user churn. 

### Overview

   **3.1. Project Proposal and Milestones:**
      - Create a project proposal outlining milestones for the tasks within the churn project.
      - Consider the audience, project goals, team dynamics, and the PACE (Plan, Analyze, Communicate, Execute) stages while planning project deliverables.
   
   **3.2. Dataframe Building and Descriptive Statistics:**
      - Build a dataframe using the churn dataset provided by Waze.
      - Examine the data type of each column in the dataset.
      - Gather descriptive statistics to understand the distribution and characteristics of the churn data.
   
   **3.3.EDA, Data Cleaning, and Visualization Selection:**
      - Perform exploratory data analysis (EDA) and data cleaning tasks for the churn project.
      - Select and build appropriate visualization type(s) to explore variables and relationships within the data.
      - Create plots and visualizations to effectively communicate insights and patterns to the Waze data team.
   
   **3.4.Hypothesis Testing for Churn Data:**
      - Conduct hypothesis testing on the churn dataset to investigate specific research questions.
      - Determine the most suitable hypothesis testing method that serves the data and the goals of the churn project.
      - Document and communicate the findings and implications of the hypothesis testing to the Waze data team.
   
   **3.5.Regression Model Building for Churn Project:**
      - Develop a regression model for the churn project using the Waze churn project data.
      - Determine the appropriate type of regression model based on the project requirements.
      - Utilize Waze's churn project data to build and train the regression model.
   
   **3.6.Final Machine Learning Model for Churn Project:**
      - Lead the final tasks for the churn project, including feature engineering, model development, and evaluation.
      - Implement advanced techniques and algorithms to improve the machine learning model's performance.
      - Evaluate the final model and provide insights and recommendations based on the evaluation results.






